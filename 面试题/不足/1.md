## 有鱼科技

### ｃ语言字节对齐的目的，和系统访问的时候是怎么访问的

<https://blog.csdn.net/lanzhihui_10086/article/details/44353381>

 对齐跟数据在内存中的位置有关。如果一个变量的内存地址正好位于它长度的整数倍，他就被称做自然对齐。比如在32位cpu下，假设一个整型变量的地址为0x00000004，那它就是自然对齐的。

需要字节对齐的根本原因在于CPU访问数据的效率问题。假设上面整型变量的地址不是自然对齐，比如为0x00000002，则CPU如果取它的值的话需要访问两次内存，第一次取从0x00000002-0x00000003的一个short，第二次取从0x00000004-0x00000005的一个short然后组合得到所要的数据，如果变量在0x00000003地址上的话则要访问三次内存，第一次为char，第二次为short，第三次为char，然后组合得到整型数据。而如果变量在自然对齐位置上，则只要一次就可以取出数据。一些系统对对齐要求非常严格，比如sparc系统，如果取未对齐的数据会发生错误.



平台原因(移植原因):不是所有的硬件平台都能访问任意地址上的任意数据的;某些硬件平台只能在某些地址
处取某些特定类型的数据,否则抛出硬件异常。



### 常用端口：

<https://blog.csdn.net/zhanghuiyu01/article/details/80830045>

[端口对照表](<https://blog.csdn.net/lendq/article/details/80138830>)

HTTP协议代理服务器常用端口号：80/8080/3128/8081/9098

FTP（文件传输）协议代理服务器常用端口号：21

SSH（安全登录）、SCP（文件传输）、端口号重定向，默认的端口号为22/tcp

Telnet（远程登录）协议代理服务器常用端口号：23

TFTP（Trivial File Transfer Protocol，不安全的文本传送），默认端口号为69/udp

HTTPS（securely transferring web pages）服务器，默认端口号为443/tcp 443/udp

Oracle 数据库，默认的端口号为1521





### **指针函数**

[指针函数，函数指针](<https://blog.csdn.net/u013476464/article/details/43277047>)

指针函数是指带指针的函数，即本质是一个**函数**。当一个函数声明其返回值为一个指针时，实际上就是返回一个地址给调用函数，以用于需要指针或地址的表达式中。



### 有语句char str[] = "abcde";请问表达式sizeof(str)的值是（）

6



### 宏和内敛函数的的区别是啥

[参考网址](<https://www.cnblogs.com/chengxuyuancc/archive/2013/04/04/2999844.html>)

内联函数是代码被插入到调用者代码处的函数。如同 #define 宏，内联函数通过避免被调用的开销来提高执行效率，尤其是它能够通过调用（“过程化集成”）被编译器优化。 宏定义不检查函数参数，返回值什么的，只是展开，相对来说，内联函数会检查参数类型，所以更安全。
　　内联函数和宏很类似，而区别在于，宏是由预处理器对宏进行替代，而内联函数是通过编译器控制来实现的。而且内联函数是真正的函数，只是在需要用到的时候，内联函数像宏一样的展开，所以取消了函数的参数压栈，减少了调用的开销。你可以象调用函数一样来调用内联函数，而不必担心会产生于处理宏的一些问题。 

当然，内联函数也有一定的局限性。就是函数中的执行代码不能太多了，如果，内联函数的函数体过大，一般的编译器会放弃内联方式，而采用普通的方式调用函数。这样，内联函数就和普通函数执行效率一样了。



###　阻塞非祖塞同步异步区别

阻塞和非阻塞:调用者在事件没有发生的时候,一直在等待事件发生,不能去处理别的任务这是阻塞。调用者在事件
没有发生的时候,可以去处理别的任务这是非阻塞。
同步和异步:调用者必须循环自去查看事件有没有发生,这种情况是同步。调用者不用自己去查看事件有没有发生,
而是等待着注册在事件上的回调函数通知自己,这种情况是异步



### 防止死锁





### c++防死锁

什么是死锁
线程死锁是指由于两个或者多个线程互相持有对方所需要的资源，导致这些线程处于等待状态，无法前往执行。当线程进入对象的synchronized代码块时，便占有了资源，直到它退出该代码块或者调用wait方法，才释放资源，在此期间，其他线程将不能进入该代码块。当线程互相持有对方所需要的资源时，会互相等待对方释放资源，如果线程都不主动释放所占有的资源，将产生死锁。

2、常见的死锁场景
一个线程已经拿到了锁，未释放锁，但是又尝试拿同样的锁，这是就会死锁
两个以上线程A B …，两个以上锁a b…，线程A已经拿到a锁，线程B已经拿到b锁，但是线程A在没有释放a锁尝试获取b锁，线程B没有释放b锁尝试获取a锁，这时也会发生死锁
3、预防死锁的办法
加锁的时候使用try_lock()，如果获取不到锁，那么就释放自己手里面得所有锁，
可以在加锁的过程中对metux进行地址的比较永远从最小地址开始加锁，这样的话就能保证所有的线程都按同一个顺序加锁，这样的话也能避免死锁

可以设置锁的属性为PTHREAD_MUTEX_ERRCHECK，这种锁如果发生死锁会返回错误，不过效率要稍微低一些





### 服务端的设计



### c++设置一个类只能在栈上申请不能在堆上申请

1、只能建立在堆上

类对象只能建立在堆上，就是不能静态建立类对象，即不能直接调用类的构造函数。
    
容易想到将构造函数设为私有。在构造函数私有之后，无法在类外部调用构造函数来构造类对象，只能使用new运算符来建立对象。然而，前面已经说过，new运算符的执行过程分为两步，C++提供new运算符的重载，其实是只允许重载operator new()函数，而operator()函数用于分配内存，无法提供构造功能。因此，这种方法不可以。
当对象建立在栈上面时，是由编译器分配内存空间的，调用构造函数来构造栈对象。当对象使用完后，编译器会调用析构函数来释放栈对象所占的空间。编译器管理了对象的整个生命周期。如果编译器无法调用类的析构函数，情况会是怎样的呢？比如，类的析构函数是私有的，编译器无法调用析构函数来释放内存。所以，编译器在为类对象分配栈空间时，会先检查类的析构函数的访问性，其实不光是析构函数，只要是非静态的函数，编译器都会进行检查。如果类的析构函数是私有的，则编译器不会在栈空间上为类对象分配内存。
 	因此，将析构函数设为私有，类对象就无法建立在栈上了。代码如下：

````c
class A
{
public:
    A(){}
    void destory(){delete this;}
private:
    ~A(){}
};
````


​        试着使用A a;来建立对象，编译报错，提示析构函数无法访问。这样就只能使用new操作符来建立对象，构造函数是公有的，可以直接调用。类中必须提供一个destory函数，来进行内存空间的释放。类对象使用完成后，必须调用destory函数。
​        上述方法的一个缺点就是，无法解决继承问题。如果A作为其它类的基类，则析构函数通常要设为virtual，然后在子类重写，以实现多态。因此析构函数不能设为private。还好C++提供了第三种访问控制，protected。将析构函数设为protected可以有效解决这个问题，类外无法访问protected成员，子类则可以访问。

另一个问题是，类的使用很不方便，使用new建立对象，却使用destory函数释放对象，而不是使用delete。（使用delete会报错，因为delete对象的指针，会调用对象的析构函数，而析构函数类外不可访问）这种使用方式比较怪异。为了统一，可以将构造函数设为protected，然后提供一个public的static函数来完成构造，这样不使用new，而是使用一个函数来构造，使用一个函数来析构。代码如下，类似于单例模式：

````c
class A
{
protected:
    A(){}
    ~A(){}
public:
    static A* create()
    {
        return new A();
    }
    void destory()
    {
        delete this;
    }
};
````


​        这样，调用create()函数在堆上创建类A对象，调用destory()函数释放内存。


2、只能建立在栈上

​		只有使用new运算符，对象才会建立在堆上，因此，只要禁用new运算符就可以实现类对象只能建立在栈上。将operator new()设为私有即可。代码如下：

```c
class A
{
private:
    void* operator new(size_t t){}     // 注意函数的第一个参数和返回值都是固定的
    void operator delete(void* ptr){} // 重载了new就需要重载delete
public:
    A(){}
    ~A(){}
};
```

### 哈希扩容

看过HashMap源码的人（大神请忽略）可能会有些疑问，HashMap究竟什么时候扩容？扩容的条件是什么？好的，接下啦我给大家介绍一下HashMap扩容相关的一些参数。

**容量（capacity）**：HashMap中数组的长度
 **加载因子(Load factor)**：HashMap在其容量自动增加前可达到多满的一种尺度，默认加载因子 = 0.75
 **扩容阈值（threshold）**：当哈希表的大小 ≥ 扩容阈值时，就会扩容哈希表
 下面再用通俗一点的话说明一下
 我们都知道HashMap的初始值是16（1,<<4）,负载因子0.75（听说这个值是经过大量实践算出来的，这个值设定最合理），初始值16指的是数组的长度（1<<4是2的4次方，这样写计算机执行更快），当数组的容量达到12（16*0.75）时，这时开始扩容，扩容为32（1<<5即2的5次方），每次扩容按照2的倍数递增，扩容是为了减少hash碰撞，让链表的数据更少（最好链表上就一个数据，即为数组的下标数据）



<http://m.nowcoder.com/discuss/72668?type=0&pos=28>

JDK8中HashMap扩容涉及到的加载因子和链表转红黑树的知识点经常被作为面试问答题，本篇将对这两个知识点进行小结。

### 链表转红黑树为什么选择数字8

在JDK8及以后的版本中，HashMap引入了红黑树结构，其底层的数据结构变成了数组+链表或数组+红黑树。添加元素时，若桶中链表个数超过8，链表会转换成红黑树。之前有写过篇幅分析选择数字8的原因，内容不够严谨。最近重新翻了一下HashMap的源码，发现其源码中有这样一段注释：

> Because TreeNodes are about twice the size of regular nodes, we use them only when bins contain enough nodes to warrant use (see TREEIFYTHRESHOLD). And when they become too small (due to removal or resizing) they are converted back to plain bins. In usages with well-distributed user hashCodes, tree bins are rarely used. Ideally, under random hashCodes, the frequency of nodes in bins follows a Poisson distribution (<http://en.wikipedia.org/wiki/Poisson>distribution) with a parameter of about 0.5 on average for the default resizing threshold of 0.75, although with a large variance because of resizing granularity. Ignoring variance, the expected occurrences of list size k are (exp(-pow(0.5, k) / factorial(k)). The first values are: 0: 0.60653066 1: 0.30326533 2: 0.07581633 3: 0.01263606 4: 0.00157952 5: 0.00015795 6: 0.00001316 7: 0.00000094 8: 0.00000006 more: less than 1 in ten million

翻译过来大概的意思是：理想情况下使用随机的哈希码，容器中节点分布在hash桶中的频率遵循泊松分布(具体可以查看<http://en.wikipedia.org/wiki/Poisson_distribution>)，按照泊松分布的计算公式计算出了桶中元素个数和概率的对照表，可以看到链表中元素个数为8时的概率已经非常小，再多的就更少了，所以原作者在选择链表元素个数时选择了8，是根据概率统计而选择的。

默认加载因子为什么选择0.75

HashMap有两个参数影响其性能：初始容量和加载因子。容量是哈希表中桶的数量，初始容量只是哈希表在创建时的容量。加载因子是哈希表在其容量自动扩容之前可以达到多满的一种度量。当哈希表中的条目数超出了加载因子与当前容量的乘积时，则要对该哈希表进行扩容、rehash操作（即重建内部数据结构），扩容后的哈希表将具有两倍的原容量。

通常，加载因子需要在时间和空间成本上寻求一种折衷。加载因子过高，例如为1，虽然减少了空间开销，提高了空间利用率，但同时也增加了查询时间成本；加载因子过低，例如0.5，虽然可以减少查询时间成本，但是空间利用率很低，同时提高了rehash操作的次数。在设置初始容量时应该考虑到映射中所需的条目数及其加载因子，以便最大限度地减少rehash操作次数，所以，一般在使用HashMap时建议根据预估值设置初始容量，减少扩容操作。

选择0.75作为默认的加载因子，完全是时间和空间成本上寻求的一种折衷选择，至于为什么不选择0.5或0.8，笔者没有找到官方的直接说明，在HashMap的源码注释中也只是说是一种折中的选择。



### epoll

 epoll 对文件描述符的操作有两种模式: LT ( level trigger )和 ET ( edge trigger )。 LT 模式是默认模式

1. LT 模式
LT(level triggered) 是缺省的工作方式,并且同时支持 block 和 no-block socket. 在这种做法中,内核告诉你一个文件
描述符是否就绪了,然后你可以对这个就绪的 fd 进行 IO 操作。如果你不作任何操作,内核还是会继续通知你的。
2. ET 模式
ET(edge-triggered) 是高速工作方式,只支持 no-block socket( 非阻塞套接字 ) 。在这种模式下,当描述符从未就绪变
为就绪时,内核通过 epoll 告诉你。然后它会假设你知道文件描述符已经就绪,并且不会再为那个文件描述符发送更
多的就绪通知,直到你做了某些操作导致那个文件描述符不再为就绪状态了 ( 比如,你在发送,接收或者接收请求,
或者发送接收的数据少于一定量时导致了一个 EWOULDBLOCK 错误)。但是请注意,如果一直不对这个 fd 作 IO 操作
( 从而导致它再次变成未就绪 ) ,内核不会发送更多的通知 (only once)
ET 模式在很大程度上减少了 epoll 事件被重复触发的次数,因此效率要比 LT 模式高。 epoll 工作在 ET 模式的时候,必须
使用非阻塞套接口,以避免由于一个文件句柄的阻塞读 / 阻塞写操作把处理多个文件描述符的任务饿死。
3 、 LT 模式与 ET 模式的区别如下:模式:当 epoll_wait 检测到描述符事件发生并将此事件通知应用程序,应用程序可以不立即处理该事件。下次调用
epoll_wait 时,会再次响应应用程序并通知此事件。 ET 模式:当 epoll_wait 检测到描述符事件发生并将此事件通知应
用程序,应用程序必须立即处理该事件。如果不处理,下次调用 epoll_wait 时,不会再次响应应用程序并通知此事
件。

### static

类的的变量或者函数加上static的应用场景



### ｔｃｐ和ｕｄｐ的区别





### 怎样用udp编程



### 一面的题忘了

### ２面写一个函数，输入n，求斐波那契（Fibonacci）数列的第n项。斐波那契数列的定义如下：　





### ２面有十万数量级的IP网段，网段是从小到大排列的，知道每个网段的首地址和末地址，但是网段的大小是随机的，然后给你个IP地址，请问怎么查到它属于哪个网段？





###　３面两个单链表相加

一次遍历

## ３面链表中位数



### ４面２３５硬币数无数个可以怎样凑齐１００











## 七牛云

close_wait发生在呢　第二次挥手后，　我打错了



epoll　ｅｔ　ｌｔ　模式



３xx错误码的含义

fork 和vfork 　还有一个带查找

const的用法

位域

四个强制指针类型转换

union共用体，，，考官说的英语，没反应过来



实现一个ｓｔｒｉｎｇ类

